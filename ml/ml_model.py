import os
import ast
import random
import joblib
import pandas as pd
from typing import Dict, Tuple

# ============================================================
# –ü–£–¢–ò –ò –§–ê–ô–õ–´
# ============================================================

MODEL_PATH = "models/code_checker_model.pkl"
TASKS_PATH = "data/tasks_300.csv"
TRAIN_DATASET_PATH = "data/python_tasks_dataset.csv"

# ============================================================
# –ó–ê–ì–†–£–ó–ö–ê ML-–ú–û–î–ï–õ–ò
# ============================================================

def load_local_model():
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é ML-–º–æ–¥–µ–ª—å –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–µ—à–µ–Ω–∏–π.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¢–û–õ–¨–ö–û –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è (train.py).
    """
    if not os.path.exists(MODEL_PATH):
        raise FileNotFoundError("ML-–º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ.")

    return joblib.load(MODEL_PATH)

# ============================================================
# –ì–ï–ù–ï–†–ê–¶–ò–Ø –ó–ê–î–ê–ù–ò–Ø (–ò–ó CSV)
# ============================================================

def generate_task() -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω–æ–µ —É—á–µ–±–Ω–æ–µ –∑–∞–¥–∞–Ω–∏–µ –∏–∑ CSV-—Ñ–∞–π–ª–∞.
    """
    if not os.path.exists(TASKS_PATH):
        raise FileNotFoundError("–§–∞–π–ª —Å –∑–∞–¥–∞–Ω–∏—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω.")

    df = pd.read_csv(TASKS_PATH)

    if "task" not in df.columns:
        raise ValueError("–í —Ñ–∞–π–ª–µ –∑–∞–¥–∞–Ω–∏–π –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ 'task'.")

    task = random.choice(df["task"].dropna().tolist())
    return str(task)

# ============================================================
# –°–¢–ê–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó PYTHON-–ö–û–î–ê
# ============================================================

def static_code_analysis(code: str) -> Tuple[bool, Dict[str, bool], str]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–π –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ Python-–∫–æ–¥–∞.
    """

    features = {
        "has_function": False,
        "has_return": False,
        "uses_import": False,
        "uses_loop": False,
        "uses_condition": False
    }

    try:
        tree = ast.parse(code)
    except SyntaxError as e:
        return False, features, f"–°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}"

    for node in ast.walk(tree):
        if isinstance(node, ast.FunctionDef):
            features["has_function"] = True
        elif isinstance(node, ast.Return):
            features["has_return"] = True
        elif isinstance(node, (ast.Import, ast.ImportFrom)):
            features["uses_import"] = True
        elif isinstance(node, (ast.For, ast.While)):
            features["uses_loop"] = True
        elif isinstance(node, ast.If):
            features["uses_condition"] = True

    return True, features, ""

# ============================================================
# –ü–†–û–í–ï–†–ö–ê –†–ï–®–ï–ù–ò–Ø (–û–°–ù–û–í–ù–ê–Ø –õ–û–ì–ò–ö–ê)
# ============================================================

def predict_local_feedback(
    model,
    task_text: str,
    solution_code: str
) -> str:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ—à–µ–Ω–∏—è:
    1) AST-–∞–Ω–∞–ª–∏–∑
    2) ML-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏
    """

    if not solution_code.strip():
        return "‚ùå –†–µ—à–µ–Ω–∏–µ –ø—É—Å—Ç–æ–µ. –í–≤–µ–¥–∏—Ç–µ –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π –∫–æ–¥."

    # ---------- –°–ò–ù–¢–ê–ö–°–ò–° ----------
    syntax_ok, features, error_msg = static_code_analysis(solution_code)

    if not syntax_ok:
        return f"‚ùå {error_msg}"

    feedback = []
    feedback.append("‚úÖ –°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–π–¥–µ–Ω.")

    # ---------- –°–¢–†–£–ö–¢–£–†–ê ----------
    feedback.append("üìê –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ä–µ—à–µ–Ω–∏—è:")

    feedback.append(
        "‚úî –§—É–Ω–∫—Ü–∏—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞."
        if features["has_function"]
        else "‚ùå –§—É–Ω–∫—Ü–∏—è –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞."
    )

    feedback.append(
        "‚úî –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è return."
        if features["has_return"]
        else "‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç return."
    )

    if features["uses_loop"]:
        feedback.append("‚Ñπ –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ü–∏–∫–ª—ã.")

    if features["uses_condition"]:
        feedback.append("‚Ñπ –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —É—Å–ª–æ–≤–∏—è.")

    if features["uses_import"]:
        feedback.append("‚Ñπ –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∏–º–ø–æ—Ä—Ç—ã.")

    # ---------- ML-–ü–†–û–í–ï–†–ö–ê ----------
    feedback.append("")
    feedback.append("üß† –†–µ–∑—É–ª—å—Ç–∞—Ç –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è:")

    try:
        ml_input = task_text + "\n" + solution_code
        prediction = int(model.predict([ml_input])[0])
    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ ML-–º–æ–¥–µ–ª–∏: {e}"

    if prediction == 1:
        feedback.append("‚úÖ –†–µ—à–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º.")
        feedback.append("üìå –ò—Ç–æ–≥: —Ä–µ—à–µ–Ω–∏–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∑–∞–¥–∞–Ω–∏—é.")
    else:
        feedback.append("‚ùå –†–µ—à–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–Ω–æ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º.")
        feedback.append("üìå –ò—Ç–æ–≥: —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ—à–µ–Ω–∏—è.")

    return "\n".join(feedback)

# ============================================================
# –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ò (–î–õ–Ø –ê–î–ú–ò–ù–ö–ò)
# ============================================================

def evaluate_model(model) -> Dict[str, float]:
    """
    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –Ω–∞ –æ–±—É—á–∞—é—â–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ.
    """

    if not os.path.exists(TRAIN_DATASET_PATH):
        raise FileNotFoundError("–î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω.")

    df = pd.read_csv(TRAIN_DATASET_PATH)

    required = {"task_text", "solution_code", "label"}
    if not required.issubset(df.columns):
        raise ValueError("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞.")

    df["input"] = df["task_text"] + "\n" + df["solution_code"]

    y_true = df["label"].astype(int)
    y_pred = model.predict(df["input"])

    accuracy = float((y_true == y_pred).mean())

    return {
        "accuracy": round(accuracy, 3),
        "records": int(len(df))
    }

# ============================================================
# –°–¢–ê–¢–ò–°–¢–ò–ö–ê
# ============================================================

def get_model_stats() -> Dict[str, int]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–∞—Ç–∞—Å–µ—Ç—É –∏ –º–æ–¥–µ–ª–∏.
    """

    trained = os.path.exists(MODEL_PATH)

    if not os.path.exists(TRAIN_DATASET_PATH):
        return {
            "trained": trained,
            "records": 0,
            "positive": 0,
            "negative": 0
        }

    df = pd.read_csv(TRAIN_DATASET_PATH)

    if "label" not in df.columns:
        return {
            "trained": trained,
            "records": len(df),
            "positive": 0,
            "negative": 0
        }

    return {
        "trained": trained,
        "records": int(len(df)),
        "positive": int((df["label"] == 1).sum()),
        "negative": int((df["label"] == 0).sum())
    }
