import os
import ast
import random
import joblib
import pandas as pd
from typing import Dict, Tuple

# ============================================================
# ÐŸÐ£Ð¢Ð˜ Ð˜ Ð¤ÐÐ™Ð›Ð«
# ============================================================

MODEL_PATH = "models/code_checker_model.pkl"
TASKS_PATH = "data/tasks_300.csv"
TRAIN_DATASET_PATH = "data/python_tasks_dataset.csv"

# ============================================================
# Ð—ÐÐ“Ð Ð£Ð—ÐšÐ ML-ÐœÐžÐ”Ð•Ð›Ð˜
# ============================================================

def load_local_model():
    if not os.path.exists(MODEL_PATH):
        raise FileNotFoundError("ML-Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°. Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ.")
    return joblib.load(MODEL_PATH)

# ============================================================
# Ð“Ð•ÐÐ•Ð ÐÐ¦Ð˜Ð¯ Ð—ÐÐ”ÐÐÐ˜Ð¯ (CSV)
# ============================================================

_last_task_id = None

def generate_task() -> str:
    global _last_task_id

    if not os.path.exists(TASKS_PATH):
        raise FileNotFoundError("Ð¤Ð°Ð¹Ð» Ñ Ð·Ð°Ð´Ð°Ð½Ð¸ÑÐ¼Ð¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½.")

    df = pd.read_csv(TASKS_PATH)

    if "task" not in df.columns:
        raise ValueError("Ð’ CSV Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ° 'task'.")

    df = df.dropna(subset=["task"])

    if df.empty:
        raise RuntimeError("Ð¤Ð°Ð¹Ð» Ð·Ð°Ð´Ð°Ð½Ð¸Ð¹ Ð¿ÑƒÑÑ‚.")

    tasks = df.to_dict(orient="records")

    if _last_task_id is not None:
        filtered = [t for t in tasks if t.get("id") != _last_task_id]
        if filtered:
            tasks = filtered

    task = random.choice(tasks)
    _last_task_id = task.get("id")

    return str(task["task"])

# ============================================================
# Ð¡Ð¢ÐÐ¢Ð˜Ð§Ð•Ð¡ÐšÐ˜Ð™ ÐÐÐÐ›Ð˜Ð— PYTHON-ÐšÐžÐ”Ð
# ============================================================

def static_code_analysis(code: str) -> Tuple[bool, Dict[str, bool], str]:
    features = {
        "has_function": False,
        "has_return": False,
        "uses_import": False,
        "uses_loop": False,
        "uses_condition": False
    }

    try:
        tree = ast.parse(code)
    except SyntaxError as e:
        return False, features, f"Ð¡Ð¸Ð½Ñ‚Ð°ÐºÑÐ¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°: {e}"

    for node in ast.walk(tree):
        if isinstance(node, ast.FunctionDef):
            features["has_function"] = True
        elif isinstance(node, ast.Return):
            features["has_return"] = True
        elif isinstance(node, (ast.Import, ast.ImportFrom)):
            features["uses_import"] = True
        elif isinstance(node, (ast.For, ast.While)):
            features["uses_loop"] = True
        elif isinstance(node, ast.If):
            features["uses_condition"] = True

    return True, features, ""

# ============================================================
# ÐŸÐ ÐžÐ’Ð•Ð ÐšÐ Ð Ð•Ð¨Ð•ÐÐ˜Ð¯
# ============================================================

def predict_local_feedback(model, task_text: str, solution_code: str) -> str:
    if not solution_code.strip():
        return "âŒ Ð ÐµÑˆÐµÐ½Ð¸Ðµ Ð¿ÑƒÑÑ‚Ð¾Ðµ. Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð½Ñ‹Ð¹ ÐºÐ¾Ð´."

    syntax_ok, features, error_msg = static_code_analysis(solution_code)

    if not syntax_ok:
        return f"âŒ {error_msg}"

    feedback = []
    feedback.append("âœ… Ð¡Ð¸Ð½Ñ‚Ð°ÐºÑÐ¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð¿Ñ€Ð¾Ð¹Ð´ÐµÐ½.")

    feedback.append("ðŸ“ ÐÐ½Ð°Ð»Ð¸Ð· ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ:")
    feedback.append("âœ” ÐžÐ±ÑŠÑÐ²Ð»ÐµÐ½Ð° Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ." if features["has_function"] else "âŒ Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð½Ðµ Ð¾Ð±ÑŠÑÐ²Ð»ÐµÐ½Ð°.")
    feedback.append("âœ” Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ return." if features["has_return"] else "âŒ ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ return.")

    if features["uses_loop"]:
        feedback.append("â„¹ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑŽÑ‚ÑÑ Ñ†Ð¸ÐºÐ»Ñ‹.")
    if features["uses_condition"]:
        feedback.append("â„¹ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑŽÑ‚ÑÑ ÑƒÑÐ»Ð¾Ð²Ð¸Ñ.")
    if features["uses_import"]:
        feedback.append("â„¹ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑŽÑ‚ÑÑ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹.")

    feedback.append("")
    feedback.append("ðŸ§  Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¼Ð°ÑˆÐ¸Ð½Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ:")

    try:
        ml_input = task_text + "\n" + solution_code
        prediction = int(model.predict([ml_input])[0])
    except Exception as e:
        return f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ML-Ð¼Ð¾Ð´ÐµÐ»Ð¸: {e}"

    if prediction == 1:
        feedback.append("âœ… Ð ÐµÑˆÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°Ð½Ð¾ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¼.")
        feedback.append("ðŸ“Œ Ð˜Ñ‚Ð¾Ð³: Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ Ð·Ð°Ð´Ð°Ð½Ð¸ÑŽ.")
    else:
        feedback.append("âŒ Ð ÐµÑˆÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°Ð½Ð¾ Ð½ÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¼.")
        feedback.append("ðŸ“Œ Ð˜Ñ‚Ð¾Ð³: Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ Ð´Ð¾Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ€ÐµÑˆÐµÐ½Ð¸Ñ.")

    return "\n".join(feedback)

# ============================================================
# ÐžÐ¦Ð•ÐÐšÐ ÐœÐžÐ”Ð•Ð›Ð˜
# ============================================================

def evaluate_model(model) -> Dict[str, float]:
    if not os.path.exists(TRAIN_DATASET_PATH):
        raise FileNotFoundError("Ð”Ð°Ñ‚Ð°ÑÐµÑ‚ Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½.")

    df = pd.read_csv(TRAIN_DATASET_PATH)

    required = {"task_text", "solution_code", "label"}
    if not required.issubset(df.columns):
        raise ValueError("ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð°Ñ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð°.")

    df["input"] = df["task_text"] + "\n" + df["solution_code"]

    y_true = df["label"].astype(int)
    y_pred = model.predict(df["input"])

    accuracy = float((y_true == y_pred).mean())

    return {
        "accuracy": round(accuracy, 3),
        "records": int(len(df))
    }

# ============================================================
# Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ
# ============================================================

def get_model_stats() -> Dict[str, int]:
    trained = os.path.exists(MODEL_PATH)

    if not os.path.exists(TRAIN_DATASET_PATH):
        return {"trained": trained, "records": 0, "positive": 0, "negative": 0}

    df = pd.read_csv(TRAIN_DATASET_PATH)

    if "label" not in df.columns:
        return {"trained": trained, "records": len(df), "positive": 0, "negative": 0}

    return {
        "trained": trained,
        "records": int(len(df)),
        "positive": int((df["label"] == 1).sum()),
        "negative": int((df["label"] == 0).sum())
    }
